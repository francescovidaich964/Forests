{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1 - Data acquisition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm_notebook, tnrange\n",
    "%matplotlib inline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tag</th>\n",
       "      <th>sp</th>\n",
       "      <th>gx</th>\n",
       "      <th>gy</th>\n",
       "      <th>dbh</th>\n",
       "      <th>pom</th>\n",
       "      <th>date</th>\n",
       "      <th>codes</th>\n",
       "      <th>status</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>105951</td>\n",
       "      <td>ACACME</td>\n",
       "      <td>610.0</td>\n",
       "      <td>104.7</td>\n",
       "      <td>119.0</td>\n",
       "      <td>1</td>\n",
       "      <td>8924.0</td>\n",
       "      <td>M</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>132160</td>\n",
       "      <td>ACACME</td>\n",
       "      <td>534.8</td>\n",
       "      <td>241.3</td>\n",
       "      <td>116.0</td>\n",
       "      <td>1</td>\n",
       "      <td>8922.0</td>\n",
       "      <td>*</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>132234</td>\n",
       "      <td>ACACME</td>\n",
       "      <td>539.4</td>\n",
       "      <td>242.3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>8922.0</td>\n",
       "      <td>DN</td>\n",
       "      <td>D</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>132235</td>\n",
       "      <td>ACACME</td>\n",
       "      <td>538.8</td>\n",
       "      <td>242.5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>8922.0</td>\n",
       "      <td>DN</td>\n",
       "      <td>D</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>191542</td>\n",
       "      <td>ACACME</td>\n",
       "      <td>282.7</td>\n",
       "      <td>177.5</td>\n",
       "      <td>75.0</td>\n",
       "      <td>1</td>\n",
       "      <td>8825.0</td>\n",
       "      <td>*</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      tag      sp     gx     gy    dbh  pom    date codes status\n",
       "0  105951  ACACME  610.0  104.7  119.0    1  8924.0     M      A\n",
       "1  132160  ACACME  534.8  241.3  116.0    1  8922.0     *      A\n",
       "2  132234  ACACME  539.4  242.3    NaN    0  8922.0    DN      D\n",
       "3  132235  ACACME  538.8  242.5    NaN    0  8922.0    DN      D\n",
       "4  191542  ACACME  282.7  177.5   75.0    1  8825.0     *      A"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"bci05.csv\")\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data = data[data[\"status\"]=='A'][[\"tag\", \"sp\", \"gx\", \"gy\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 299 different species\n"
     ]
    }
   ],
   "source": [
    "# 1) Species spotting\n",
    "types = data['sp'].value_counts().keys() \n",
    "S = len(types)\n",
    "print(\"There are {} different species\".format(S))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2 - Statistics on subplots\n",
    "\n",
    "Now we divide the total area of study (sampled plot) in 200 subplots of the same area.\n",
    "To do so we add two columns to the dataset, called $i$ and $j$, that are the result of division without rest respectively of $gx$ and $gy$ for 50 (0.5 hectars in each axis). Then we use some methods of pandas to encode in a 3D matrix the aboundance $x_k$ of each of the S species for each subplot $(i,j)$ and from that we can obtain the average presence of each species."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2) Subsampling\n",
    "# 50 * 50 meters\n",
    "data[\"i\"], data[\"j\"] = data[\"gx\"]//50, data[\"gy\"]//50\n",
    "# a)\n",
    "cell_pop = data.groupby([\"i\", \"j\"])[\"sp\"].value_counts()\n",
    "# b) shaping them in a matrix\n",
    "cell_pop_M = cell_pop.unstack().stack(dropna = False).fillna(0).astype(int)\n",
    "cell_pop_M = np.array(cell_pop_M).reshape(20, 10, 299) # (i, j, specie)\n",
    "\n",
    "# this prints are just for understanding how to work with this dataset\n",
    "#print(\"Presence and aboundance in subplot (0,0) : \\n\", cell_pop_M[0,0,:], '\\n')\n",
    "#print(\"Aboundances of the various species: \\n\", cell_pop_M.sum(axis=(0,1)), '\\n')\n",
    "\n",
    "p_i = np.count_nonzero(cell_pop_M, axis = (0,1))/200\n",
    "#print(\"Absolute presence for each species: \\n\", presence, '\\n')\n",
    "#print(\"Relative presence for each species: \\n\", p_i, '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And the average squared difference between present and absent species in a subplot (that will be used as a constraint in section 4):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pairing_p(configs):\n",
    "    # In each subplot there are more absent species than present (just an observation)\n",
    "    # S+ - S-\n",
    "    S_present = np.count_nonzero(configs, axis = (1)).flatten()\n",
    "    # S_absent = S - S_present -> S_pm = 2*S_present - S\n",
    "    S_pm = 2*S_present - S # Broadcasting\n",
    "    # constraint C_0 = < (S+ - S-)^2 >\n",
    "    return np.mean(np.power(S_pm,2))\n",
    "\n",
    "\n",
    "C0_exp = pairing_p(cell_pop_M.reshape(200, 299)) /299  #VALUTARE SE DIVIDERE PER S  <-------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3 - Max Ent 1\n",
    "\n",
    "### Hamiltonian of the system for our constraints.\n",
    "\n",
    "We start considering a generic entropy:\n",
    "\n",
    "$$ S[\\{p_a\\}_{i=1,\\ldots,n}] = -K \\sum_{a=1}^n p_a ln(p_a), K > 0$$\n",
    "\n",
    "and following constraints:\n",
    "\n",
    "$$ \\sum_{a=1}^n p_a - 1 = 0 $$\n",
    "\n",
    "$$\\sum_{a=1}^n  p_a f_r(x_a) - <f_r(x)>_{obs} = 0 $$\n",
    "\n",
    "On the PDF we show that the corresponding Hamiltonian is:\n",
    "\n",
    "$$H(x_a, \\vec{\\lambda}) = - \\sum_{r=1}^{m}\\lambda_i f_i(x_a)$$\n",
    "\n",
    "\n",
    "### Analytical derivation of the tuned Lagrangian multipliers as functions of the constraints.\n",
    "\n",
    "Adopting the notation to our specific model, we set $K=1$, and rename:\n",
    "\n",
    "$x_a \\rightarrow \\vec{\\sigma^{(a)}}, m \\rightarrow S, f_r(x) \\rightarrow \\pi_i(\\vec{\\sigma}) = \\sigma_i$\n",
    "\n",
    "We start considering the following Hamiltonian:\n",
    "\n",
    "$H(\\vec{\\sigma}, \\vec{\\lambda}) = - \\sum_{i=1}^{S}\\lambda_i f_i(\\sigma) = - \\sum_{i=1}^{S}\\lambda_i \\sigma_i $\n",
    "\n",
    "Manipulating the partition function\n",
    "\n",
    "$$Z(\\vec{\\lambda}) = \\sum_{\\{\\vec{\\sigma}\\}} \\exp\\{\\sum_{i=1}^S \\lambda_i \\sigma_i\\} = \\\n",
    "    \\sum_{\\{\\vec{\\sigma}\\}} \\prod_{i=1}^S\\exp\\{\\lambda_i \\sigma_i\\} = \\\n",
    "    \\prod_{i=1}^S \\sum_{\\sigma_i = \\pm 1} \\exp\\{\\lambda_i \\sigma_i\\}  = \\\n",
    "    2^S \\prod_{i=1}^S \\cosh(\\lambda_i)$$\n",
    "\n",
    "Hence we can compute analytically the expected value for each variable $\\sigma_i$ for a given value of $\\vec{\\lambda}$\n",
    "\n",
    "$$ <\\sigma_i>_{model(\\vec{\\lambda})} = \\sum_{\\{\\vec{\\sigma}\\}} \\sigma_i P(\\vec{\\sigma}/\\vec{\\lambda}) = \\\n",
    "\\frac{\\sum_{\\sigma_i \\pm 1} \\sigma_i e^{\\lambda_i \\sigma_i}}{2 cosh(\\lambda_i)} = tanh(\\lambda_i) $$\n",
    "\n",
    "Now we impose $\\forall i$ $m_i = <\\sigma_i>_{model(\\vec{\\lambda})}$ \n",
    "\n",
    "$m_i = tanh(\\lambda_i) $\n",
    "\n",
    "and inverting the system we find\n",
    "\n",
    "$ \\lambda_i = +\\frac{1}{2} \\cdot ln(\\frac{1 + m_i}{1 - m_i} )$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we apply the formula just obtained to compute the lagrangian parameters for the model Max Ent 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "m_i = 2*p_i - 1\n",
    "eps = 10e-06 # a small regularization in order to avoid devergences\n",
    "l_i = 0.5*np.log((1 - m_i + eps)/(1 + m_i + eps))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4 - Max Ent 2\n",
    "\n",
    "Now we consider a new Hamiltonian\n",
    "\n",
    "$H(\\vec{\\sigma}, \\vec{\\lambda}, K) = - \\frac{K}{S}\\sum_{i,j}\\sigma_i\\sigma_j - \\sum_{i=1}^{S}\\lambda_i \\sigma_i$\n",
    "\n",
    "\n",
    "\n",
    "### Constraints for Max Ent 2\n",
    "\n",
    "The constraints that we are going to use are:\n",
    "* $m_i = <\\sigma_i>_{model} = C_i(\\vec{\\sigma}) $ with coupled parameters $\\lambda_i, i = 1,\\ldots, S$\n",
    "* $<(S_+ - S_-)^2>_{exp} = <(\\sum_{j=1}^{S}\\sigma_j)^2>_{model} = C_0(\\vec{\\sigma})$ with coupled parameter $\\lambda_0 = K/S$\n",
    "\n",
    "To initialize the Lagrange multipliers we have two possible choices: extracting them from a gaussian distribution centered in 0 or to take the initial $\\lambda_i$ as the one of the previous point and for $K'$ using a gaussian with variance that is a funtion of S. [WORK IN PROGRESS]\n",
    "\n",
    "### Gradient descent function\n",
    "\n",
    "The objective function that we want to minimize is the Kullback–Leibler divergence $D_{KL}(P_{exp}/P_{model})$.\n",
    "\n",
    "The derivatives of the KL-divergence w.r.t. the Lagrangian multipliers are:\n",
    "\n",
    "$$ \\frac{\\partial D_{KL}}{\\partial \\lambda_a} = <C_a(\\vec{\\sigma})>_{model}-<C_a(\\vec{\\sigma})>_{exp} $$\n",
    "\n",
    "More in concrete:\n",
    "\n",
    "$$\\frac{\\partial D_{KL}(t)}{\\partial \\lambda_0} = <(\\sum_{j=1}^{S}\\sigma_j)^2>_{model(t)} - <(S_+ - S_-)^2>_{exp}  $$\n",
    "\n",
    "$$\\frac{\\partial D_{KL}(t)}{\\partial \\lambda_i} = <\\sigma_i>_{model(t)} - m_i $$\n",
    "\n",
    "\n",
    "Thus the update rule for gradient descent will be:\n",
    "\n",
    "$$\\lambda_a(t+1) \\leftarrow \\lambda_a(t) - \\eta \\cdot \\frac{\\partial D_{KL}(t)}{\\partial \\lambda_a}$$\n",
    "\n",
    "\n",
    "### Stopping criteria\n",
    "Then we want to run the cycle of Metropolis and gradient descent until a stopping criteria is met.\n",
    "Possible choices are:\n",
    "* fixed number of iterations\n",
    "* margin of improvement under a certain threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FUNCTIONS FOR SAMPLING GOOD CONFIGS WITH METROPOLIS\n",
    "\"\"\"\n",
    "def compute_dE(test_config, index, lambdas): \n",
    "    \n",
    "    # Compute how many species are presents in in the config (how many spins are +1)\n",
    "    S_present = np.count_nonzero(test_config+1)\n",
    "       \n",
    "    # Compute dE (each term should have sign '-' if we consider negative H, as defined above)\n",
    "    dE_standard = 2*lambdas[index+1]*test_config[index]\n",
    "    dE_pairing  = lambdas[0]*2*test_config[index]*(2*S_present-299-test_config[index])\n",
    "    dE = dE_standard + dE_pairing\n",
    "    #print('standard:', dE_standard, '   pairing:', dE_pairing)\n",
    "    print(dE)\n",
    "    return(dE)\n",
    "\n",
    "\"\"\"\n",
    "def compute_dE(test_config, index, lambdas):\n",
    "    \n",
    "    # Compute E_new\n",
    "    prod_sum = np.sum(np.outer(test_config,test_config))\n",
    "    E_new = np.dot(test_config, lambdas[1:]) + prod_sum*lambdas[0]\n",
    "    \n",
    "    # Return to old config\n",
    "    test_config[index] = -test_config[index]\n",
    "    \n",
    "    # Compute E_old\n",
    "    prod_sum = np.sum(np.outer(test_config,test_config))\n",
    "    E_old = np.dot(test_config, lambdas[1:]) + prod_sum*lambdas[0]\n",
    "    \n",
    "    # Compute and print dE\n",
    "    dE = E_new-E_old\n",
    "    print(-dE)\n",
    "    return(-dE)\n",
    "  \n",
    "    \n",
    "    \n",
    "def acceptance_test(config, index, lambdas):\n",
    "    \n",
    "    #flip spin at 'index' and compute dE between new and old config\n",
    "    config[index] = -config[index]\n",
    "    dE = compute_dE(config, index, lambdas)\n",
    "    \n",
    "    #Acceptance Test\n",
    "    if dE<0:\n",
    "        return (True)\n",
    "    else:\n",
    "        prob_acc = np.random.random()\n",
    "        if prob_acc < np.exp(-dE):\n",
    "            return (True)\n",
    "        else:\n",
    "            return (False)\n",
    "        \n",
    "    \n",
    "    \n",
    "def metropolis_sample(lambdas, max_acc, N, M=100):\n",
    "     \n",
    "    #First, generate a random configuration and initialize things\n",
    "    configuration = np.random.choice([+1,-1], size = 299)\n",
    "    flip_spins = np.random.randint(low = 0, high = 299, size = M)\n",
    "    acc_rate = 1\n",
    "\n",
    "    # --- CALIBRATE --- until acc_rate reaches the treshold\n",
    "    while (acc_rate > max_acc):\n",
    "        \n",
    "        #Count how many flips are accepted (over M flips)\n",
    "        acc_flips = 0\n",
    "        for i in flip_spins:\n",
    "            \n",
    "            #Test acceptance of the config after flipping spin i \n",
    "            if acceptance_test(configuration, i, lambdas):\n",
    "                configuration[i] = -configuration[i]\n",
    "                acc_flips += 1\n",
    "            # If flip is not accepted, the configuration is unchanged\n",
    "            \n",
    "        #Compute acceptance rate\n",
    "        acc_rate = acc_flips/M\n",
    "        #print(acc_rate)\n",
    "    \n",
    "    # --- SAMPLE --- N configs continuing flipping one spin at time\n",
    "    sampled_configs = np.zeros(shape=(N,299))\n",
    "    sample_index = 0\n",
    "    \n",
    "    while (sample_index < N):\n",
    "        \n",
    "        #choose at random a spin to flip\n",
    "        spin_index = np.random.randint(low = 0, high = 299)\n",
    "        \n",
    "        #Test acceptance of the config after flipping spin, if accepted save it in 'sample_configs'\n",
    "        if acceptance_test(configuration, spin_index, lambdas):\n",
    "            configuration[i] = -configuration[i]\n",
    "            sampled_configs[sample_index] = configuration\n",
    "            sample_index += 1\n",
    "            \n",
    "    return (sampled_configs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FUNCTION TO COMPUTE TERMS OF THE KULLBACK-LEIBLER DIVERGENCE\n",
    "\n",
    "def KL_divergence(configs, exp_constraints):\n",
    "    \n",
    "    # Compute pairing constraint\n",
    "    spin_sums = np.sum(configs, axis=1)\n",
    "    C0_model = np.mean(np.power(spin_sums,2)) /299  #VALUTARE SE DIVIDERE PER S  <-------------\n",
    "    \n",
    "    # Compute 'single-specie' constraints\n",
    "    Ci_model = np.mean(configs, axis=0)\n",
    "    \n",
    "    # Compute KL divergence Terms\n",
    "    KL_div = np.zeros(300)\n",
    "    KL_div[0]  = C0_model - exp_constraints[0]\n",
    "    KL_div[1:] = Ci_model - exp_constraints[1:]\n",
    "    \n",
    "    return KL_div\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e4cd4dc7313241b98bacab1bf4ca5c76",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=1000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "______ERROR_____:  31.065301952023734\n",
      "______ERROR_____:  27.854631420114497\n",
      "______ERROR_____:  24.244549747747456\n",
      "______ERROR_____:  29.947503825367647\n",
      "______ERROR_____:  22.41493403876815\n",
      "______ERROR_____:  22.422687672597057\n",
      "______ERROR_____:  21.66581463758626\n",
      "______ERROR_____:  21.540369632628106\n",
      "______ERROR_____:  24.045595380620796\n",
      "______ERROR_____:  29.31881623412531\n",
      "______ERROR_____:  27.901980065049685\n",
      "______ERROR_____:  21.223875008651973\n",
      "______ERROR_____:  22.982330689254454\n",
      "______ERROR_____:  28.94119875489627\n",
      "______ERROR_____:  34.815630649895105\n",
      "______ERROR_____:  29.148286349624723\n",
      "______ERROR_____:  29.386760324419065\n",
      "______ERROR_____:  29.623530849556587\n",
      "______ERROR_____:  23.15540693624021\n",
      "______ERROR_____:  20.704031550952486\n",
      "______ERROR_____:  23.379879685746374\n",
      "______ERROR_____:  35.08685661195941\n",
      "______ERROR_____:  29.053278392814978\n",
      "______ERROR_____:  20.631970154859218\n",
      "______ERROR_____:  21.023023662409912\n",
      "______ERROR_____:  28.843415143143485\n",
      "______ERROR_____:  32.023680896042606\n",
      "______ERROR_____:  29.353408611602823\n",
      "______ERROR_____:  25.241458128103286\n",
      "______ERROR_____:  25.48845372315017\n",
      "______ERROR_____:  29.197304620798796\n",
      "______ERROR_____:  20.44916742824524\n",
      "______ERROR_____:  23.187774157578847\n",
      "______ERROR_____:  24.881342669134035\n",
      "______ERROR_____:  23.722958797754888\n",
      "______ERROR_____:  27.985433875122755\n",
      "______ERROR_____:  23.82683765150133\n",
      "______ERROR_____:  22.666126776320528\n",
      "______ERROR_____:  23.23443078967023\n",
      "______ERROR_____:  37.66931668842308\n",
      "______ERROR_____:  28.812722630296662\n",
      "______ERROR_____:  28.778005142723682\n",
      "______ERROR_____:  24.594884268453285\n",
      "______ERROR_____:  20.606632501217526\n",
      "______ERROR_____:  27.43694502970712\n",
      "______ERROR_____:  22.64139727099195\n",
      "______ERROR_____:  20.519972416217495\n",
      "______ERROR_____:  27.290863094317693\n",
      "______ERROR_____:  25.799818937514505\n",
      "______ERROR_____:  29.76377995348909\n",
      "______ERROR_____:  21.966965313240188\n",
      "______ERROR_____:  21.383128687612608\n",
      "______ERROR_____:  29.656409039526665\n",
      "______ERROR_____:  23.501716048164063\n",
      "______ERROR_____:  31.8109436850208\n",
      "______ERROR_____:  29.5452635310589\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-0ed65c2aad60>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0;31m# Sample N configurations with metropolis\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m     \u001b[0mgood_configs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmetropolis_sample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlambdas\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_acc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mN\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[0;31m# Compute all terms of Kullback–Leibler divergences\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-8-016a5f590cd9>\u001b[0m in \u001b[0;36mmetropolis_sample\u001b[0;34m(lambdas, max_acc, N, M)\u001b[0m\n\u001b[1;32m     87\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m         \u001b[0;31m#Test acceptance of the config after flipping spin, if accepted save it in 'sample_configs'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 89\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0macceptance_test\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfiguration\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mspin_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlambdas\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     90\u001b[0m             \u001b[0mconfiguration\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0mconfiguration\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m             \u001b[0msampled_configs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msample_index\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconfiguration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-8-016a5f590cd9>\u001b[0m in \u001b[0;36macceptance_test\u001b[0;34m(config, index, lambdas)\u001b[0m\n\u001b[1;32m     39\u001b[0m     \u001b[0;31m#flip spin at 'index' and compute dE between new and old config\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m     \u001b[0mconfig\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 41\u001b[0;31m     \u001b[0mdE\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompute_dE\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlambdas\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     42\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m     \u001b[0;31m#Acceptance Test\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-8-016a5f590cd9>\u001b[0m in \u001b[0;36mcompute_dE\u001b[0;34m(test_config, index, lambdas)\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0;31m# Compute E_new\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m     \u001b[0mprod_sum\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mouter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_config\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtest_config\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m     \u001b[0mE_new\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_config\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlambdas\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mprod_sum\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mlambdas\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/numpy/core/numeric.py\u001b[0m in \u001b[0;36mouter\u001b[0;34m(a, b, out)\u001b[0m\n\u001b[1;32m   1127\u001b[0m     \u001b[0ma\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1128\u001b[0m     \u001b[0mb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1129\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mmultiply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mravel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnewaxis\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mravel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnewaxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1130\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1131\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Define constants\n",
    "eta = 0.5\n",
    "max_acc = 0.15\n",
    "N = 100\n",
    "iterations = 1000\n",
    "\n",
    "# vectors to save results\n",
    "every_lambdas = np.zeros((iterations, 300))\n",
    "errors = np.zeros(iterations)\n",
    "\n",
    "# We start with l_i from point 3 and random l_0\n",
    "l_0 = np.random.uniform(-1,1)\n",
    "lambdas = np.concatenate(([l_0], l_i))\n",
    "\n",
    "for i in tnrange(iterations):\n",
    "    \n",
    "    # Sample N configurations with metropolis\n",
    "    good_configs = metropolis_sample(lambdas, max_acc, N)\n",
    "\n",
    "    # Compute all terms of Kullback–Leibler divergences \n",
    "    exp_constraints = np.concatenate(([C0_exp], m_i))\n",
    "    KL_div_values = KL_divergence(good_configs, exp_constraints)\n",
    "    \n",
    "    # Gradient descent to update lambdas\n",
    "    lambdas = lambdas - eta*KL_div_values\n",
    "    every_lambdas[i] = lambdas\n",
    "    \n",
    "    # Estimate error as the norm of the gradient\n",
    "    errors[i] = np.linalg.norm(KL_div_values)\n",
    "    print('______ERROR_____: ',errors[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.plot(errors)\n",
    "plt.show()\n",
    "plt.plot(every_lambdas[:,0])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "oldHeight": 506.21666000000005,
   "position": {
    "height": "40px",
    "left": "994.367px",
    "right": "14.6333px",
    "top": "94px",
    "width": "516.367px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "varInspector_section_display": "none",
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
